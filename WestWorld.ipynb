{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5cc10c04-42eb-4566-95eb-be6ff6badf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import random as np_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1ecee55d-e980-4401-bb52-08d51319cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np_random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6013f2e9-c870-4b84-b424-4790a31ae775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda activate dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d6218d4-2e46-4411-b950-0a20b6807b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load GPT-2 tokenizer and fine-tuned model\n",
    "model_checkpoint = \"distilgpt2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\".\", pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7974f3b3-0e53-4c63-8695-753f538fabeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t    func_for_tom.py  pytorch_model.bin\n",
      "func_for_tom.ipynb  philosophers     WestWorld.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b71b0dd4-2aaf-4d72-9590-a561ce79e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilgpt2\"\n",
    "tokenizer_republic = GPT2Tokenizer.from_pretrained(\"./philosophers/republic\", use_fast=True)\n",
    "tokenizer_zarathustra = GPT2Tokenizer.from_pretrained(\"./philosophers/zarathustra\", use_fast=True)\n",
    "tokenizer_tao = GPT2Tokenizer.from_pretrained(\"./philosophers/tao\", use_fast=True)\n",
    "model_republic = AutoModelForCausalLM.from_pretrained(\"./philosophers/republic\", pad_token_id=tokenizer.eos_token_id)\n",
    "model_zarathustra = AutoModelForCausalLM.from_pretrained(\"./philosophers/zarathustra\", pad_token_id=tokenizer.eos_token_id)\n",
    "model_tao = AutoModelForCausalLM.from_pretrained(\"./philosophers/tao\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fc61ed8d-e665-43f7-b3e0-bc3421b1fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"republic\": model_republic,\n",
    "    \"zarathustra\": model_zarathustra,\n",
    "    \"tao\": model_tao\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5f9a7647-02a2-449d-9a32-ffdaf567a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WiseWorld:\n",
    "    \"\"\"\n",
    "    * Environment where the hosts are. \n",
    "    * Controls the flow of hosts thinking vs. speaking vs. listening. \n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        self.active_hosts = []\n",
    "    \n",
    "    def add_host(self, new_host, host_name):\n",
    "        # TODO: When new_host is dict, require name too\n",
    "        self.active_hosts.append(new_host)\n",
    "        pass\n",
    "    \n",
    "# COMMENTING OUT UNTIL USE     \n",
    "#     def retire_host():\n",
    "#         # TODO: When active_hosts is dict, remove\n",
    "#         pass\n",
    "    \n",
    "    def run_society(self,num_loops=10):\n",
    "        output = []\n",
    "        for _ in range(num_loops):\n",
    "            output.append(self.host_thinking_cycle(2))\n",
    "        return output\n",
    "        \n",
    "    def host_thinking_cycle(self, num_thinks):\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for host in self.active_hosts:\n",
    "            output.append([host.get_name() + \": \"])\n",
    "        \n",
    "        # Thinking\n",
    "        for i, host in enumerate(self.active_hosts):\n",
    "            for _ in range(num_thinks):\n",
    "                output[i].append(host.think())\n",
    "            \n",
    "        # Speaking/Listening\n",
    "        random_host_id = random.randint(0,len(self.active_hosts)-1)\n",
    "        speaker = self.active_hosts[random_host_id]\n",
    "        speaker_name = speaker.get_name()\n",
    "        print(speaker_name + \" speaks:\")\n",
    "        speech = speaker.speak()\n",
    "        \n",
    "        for i, host in enumerate(self.active_hosts):\n",
    "            host.listen(speech)\n",
    "            output[i].append(speech)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# COMMENTING OUT UNTIL USE            \n",
    "#     def reprogram(new_program):\n",
    "#         # Assumes you want to reprogram all hosts\n",
    "#         # TODO: Make this so we can selectively reprogram one\n",
    "#         for host in self.active_hosts:\n",
    "#             host.mind_control(new_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "74932b2e-cf78-4361-ace7-b4525a56ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SETUP\n",
    "\"\"\"\n",
    "\n",
    "plato_seed = \"And now, at last, we have reached firm ground, and are able to infer that the virtues of the State and of the individual are the same.\"\n",
    "nietzsche_seed = \"When Zarathustra was thirty years old, he left his home and the lake of his home, and went into the mountains.\"\n",
    "lao_tzu_seed = \"The Tao that can be trodden is not the enduring and unchanging Tao.\"\n",
    "\n",
    "universal_prompt = \"What is the meaning of life?\"\n",
    "\n",
    "wiseworld = WiseWorld()\n",
    "plato = Host(model_plato, \"PLATO\", universal_prompt)\n",
    "nietzsche = Host(model_zarathustra, \"NIETZSCHE\", universal_prompt)\n",
    "lao_tzu = Host(model_tao, \"LAO TZU\", universal_prompt)\n",
    "\n",
    "wiseworld.add_host(plato, \"PLATO\")\n",
    "wiseworld.add_host(lao_tzu, \"LAO TZU\")\n",
    "wiseworld.add_host(nietzsche, \"NIETZSCHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4e6d448d-a51f-4215-8d57-6dde8bdf19b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAO TZU speaks:\n",
      "LAO TZU speaks:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['PLATO: ',\n",
       "   '--Or is it just that living itself spoilt by living experiences?',\n",
       "   ' Wellthen, my brethren, if one should live indanger, seek shelterfrom itself in a forest! And if one would not love himself, seek a refuge in a forest?',\n",
       "   '--and should one love oneself only as a means to living?'],\n",
       "  ['LAO TZU: ',\n",
       "   ' To learn from oneself and leave oneself in order to be able to livefreely, is the virtue of the slave-master who never enlighteth himself.',\n",
       "   'Or is it misery without purpose?',\n",
       "   '--and should one love oneself only as a means to living?'],\n",
       "  ['NIETZSCHE: ',\n",
       "   ' Or is itdesirability to live among apes and wolves?',\n",
       "   ' Must one not live for himself?',\n",
       "   '--and should one love oneself only as a means to living?']],\n",
       " [['PLATO: ',\n",
       "   'Or is it bad to live among animals which one should not love?',\n",
       "   '',\n",
       "   ' And where there are novens for living,how should one live without committing a sin?'],\n",
       "  ['LAO TZU: ',\n",
       "   ' If so--life should be a means to all who are burdensome to the onetrue master.',\n",
       "   ' Or is itdesirableness?',\n",
       "   ' And where there are novens for living,how should one live without committing a sin?'],\n",
       "  ['NIETZSCHE: ',\n",
       "   ' If one already liveth only in badlandsand terrible things, then one ought to live among greenmountains.',\n",
       "   '--Even the best living ones should live without regard to the sick and infected.',\n",
       "   ' And where there are novens for living,how should one live without committing a sin?']]]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = wiseworld.run_society(10)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0016e55b-3f90-49d7-b4cd-273f59c031cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the meaning of life?'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plato.get_monologue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9d12cbb4-61fe-434e-99b0-2a962a355e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the meaning of life?'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nietzsche.get_monologue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "22f096bd-a524-46ee-a47f-4a73936b6670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the meaning of life?'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lao_tzu.get_monologue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bfba646d-23a1-4e0d-ae72-2aa69f681bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Host:\n",
    "    \"\"\"\n",
    "    * AI agent we are interested in.\n",
    "    * At each time step, either speaks, listens or thinks. \n",
    "    \"\"\"\n",
    "    def __init__(self, model, name=\"Philosopher\", seed_sentence=\"Hello, world. \", temperature=1.0):\n",
    "        self.name = name # Type: str\n",
    "        self.internal_monologue = seed_sentence # Type: str\n",
    "        self.memory_size = 0 # Type: int\n",
    "        self.seed_sentence = seed_sentence # Type: str\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        \n",
    "    def update_monologue(self,new_thought):\n",
    "        \"\"\"\n",
    "        Even though internal_monologue is list of sentences, we \n",
    "            want to limit its number of words in monologue, to account for long sentences.\n",
    "            GPT2 model has an approx max number of words (what is it?), so when exceed\n",
    "            need to pop off sentences until the total number of words is less. \n",
    "        \"\"\"\n",
    "        max_words = 900 # Model can take 1024 subwords, so this is conservative\n",
    "        new_thought_num_words = len(new_thought.split())\n",
    "        self.memory_size += new_thought_num_words\n",
    "        self.internal_monologue += new_thought\n",
    "        while self.memory_size > max_words:\n",
    "            delete_chunk_size = 15\n",
    "            diff = memory_size - max_words\n",
    "            self.internal_monologue = self.internal_monologue[delete_chunk_size:]\n",
    "            popped_sentence_num_words = self.internal_monologue.pop(0)\n",
    "            self.memory_size -= popped_sentence_num_words\n",
    "            if len(self.internal_monologue) < delete_chunk_size : break\n",
    "        return self.internal_monologue\n",
    "        \n",
    "    def get_monologue(self):\n",
    "        return self.internal_monologue\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "        \n",
    "    def listen(self,new_thought):\n",
    "        self.update_monologue(new_thought)\n",
    "        pass\n",
    "    \n",
    "    def speak(self):\n",
    "        speech = self.think(False) # Don't update now; will update all together\n",
    "        return speech\n",
    "    \n",
    "    def think(self, update=True):\n",
    "        thought = self.generate_sentence(has_input = False)\n",
    "        if update: self.update_monologue(thought)\n",
    "        return thought\n",
    "    \n",
    "# COMMENTING OUT UNTIL USE     \n",
    "#     def mind_control(self, new_thought):\n",
    "#         # For maintenance to control them. \n",
    "#         # update_monologue is for other functions to call. \n",
    "#         # TODO indicate that update_monologue is private, python style. \n",
    "#         self.update_monologue(new_thought)\n",
    "    \n",
    "    def generate_sentence(self,input_text=\"\", has_input=True, memory=True):\n",
    "        \"\"\"\n",
    "        Arg: input_text: (str) The text to add to internal monologue\n",
    "        Return: output_sentence: (str) The response sentence\n",
    "        \"\"\"\n",
    "        if has_input: \n",
    "            if memory:\n",
    "                new_internal_monologue = self.update_monologue(input_text)\n",
    "            else: new_internal_monologue = input_text # Don't record to memory\n",
    "        else: \n",
    "            new_internal_monologue = self.internal_monologue\n",
    "        \n",
    "        input_tokens = tokenizer.encode(new_internal_monologue, return_tensors='pt')\n",
    "        input = tokenizer.encode(string_input_sentence, return_tensors='pt')\n",
    "        \n",
    "        # set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "        sample_outputs = model_zarathustra.generate(\n",
    "            input_ids=input,\n",
    "            do_sample=True, \n",
    "            max_length=100, \n",
    "        #     top_k=50, \n",
    "        #     top_p=0.95,\n",
    "            num_return_sequences=1,\n",
    "        #     temperature = 1.0,\n",
    "        )\n",
    "\n",
    "        output_initial = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "        len_input = len(string_input_sentence)\n",
    "        output_trim = output_initial[len_input:]\n",
    "        end_period = output_trim.find(\".\")\n",
    "        end_question = output_trim.find(\"?\")\n",
    "        if (end_period > 0) and (end_question > 0): \n",
    "            end = min(end_period, end_question)\n",
    "        elif end_period < 0: end = end_question\n",
    "        elif end_question < 0: end = end_period\n",
    "        else: end = -1\n",
    "        output = output_trim[:end+1]\n",
    "        return output\n",
    "# COMMENTING OUT UNTIL USE     \n",
    "#     def change_temperature(new_temp):\n",
    "#         self.temperature = new_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad486f98-4770-4e0f-befb-b61db9dc896f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6abc52c-906d-4e1b-91e3-3d5a38afc394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14616a6c-8544-44fb-b6cc-ca59eef4dee6",
   "metadata": {},
   "source": [
    "# The Forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9dfacf27-e747-4b79-b630-86705dc55b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "84\n",
      " Wherewith all innocence striveth wanteth to live, and all weariness wanteth to live?\n"
     ]
    }
   ],
   "source": [
    "string_input_sentence = \"How should one best live life?\"\n",
    "input = tokenizer.encode(string_input_sentence, return_tensors='pt')\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "sample_outputs = model_zarathustra.generate(\n",
    "    input_ids=input,\n",
    "    do_sample=True, \n",
    "    max_length=100, \n",
    "#     top_k=50, \n",
    "#     top_p=0.95,\n",
    "    num_return_sequences=5,\n",
    "#     temperature = 1.0,\n",
    "    repetition_penalty = 1.0\n",
    ")\n",
    "\n",
    "output_initial = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "len_input = len(string_input_sentence)\n",
    "print(len_input)\n",
    "output_trim = output_initial[len_input:]\n",
    "end_period = output_trim.find(\".\")\n",
    "end_question = output_trim.find(\"?\")\n",
    "if (end_period > 0) and (end_question > 0): \n",
    "    end = min(end_period, end_question)\n",
    "elif end_period < 0: end = end_question\n",
    "elif end_question < 0: end = end_period\n",
    "else: end = -1\n",
    "output = output_trim[:end+1]\n",
    "print(end)\n",
    "print(output_trim[:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d784e0d4-2f15-4735-a33c-972286e91d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2437,   815,   530,  1266,  2107,  1204,    30,   220,   554,   262,\n",
       "         2456,   286,  7361,  3700, 14909,    25,   198,     1, 10418,   389,\n",
       "          588, 19435,    11,   290,   262, 24276,   481, 19861,   511, 24276,\n",
       "          526,    18,    13,  4162,   815,   530,   523,   881,  3252,  1918,\n",
       "          307,  7207,   268,   262,   661,    30,   220,  4362,   286,   262])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c127906f-d294-4138-9431-318cb76eb194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How should one best live life? Is notlife so repast and chastiseless and almost unrighteous, that which is profited by indulging andmanaging? Is this the condition of which we should choose--and when a man expireshis abode is not with him but with his owneyes, and with the pattern and manner in which he ought tolive, and is perfected by his manifold works?Certainly, he said, and he who does not partake of this lifehas only a better life, but a worse; if he live many years, if he live a great deal longer, will he not only live happy here, but a barren land, which is full of miseryand pain?From what have you said? he'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c424d-2b55-4c97-be7e-e1642778fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_for_tom(string_input_sentence):\n",
    "    \n",
    "    input = tokenizer.encode(string_input_sentence, return_tensors='pt')\n",
    "\n",
    "    # set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "    sample_outputs = model.generate(\n",
    "        input_ids=input,\n",
    "        do_sample=True, \n",
    "        max_length=50, \n",
    "        top_k=50, \n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1,\n",
    "        temperature = 0.7\n",
    "    )\n",
    "\n",
    "    output = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    end = output.find(\".\")\n",
    "    len_input = len(string_input_sentence)\n",
    "    output_trim = output[len_input+1:end+1]\n",
    "    if end == -1: output_trim = output[len_input+1:]\n",
    "    return output_trim.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147dfc87-b51f-4623-ae26-8065a0f21e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
