{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "philosophers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "124ot1FLXk6knmConCV8ChCHNsJNc524-",
      "authorship_tag": "ABX9TyOqf1dyMQOYdHuat8prFKo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benfrancis314/amath_563/blob/main/philosophers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guldfrmfdWOx"
      },
      "source": [
        "# Fine tune distilGPT-2 on Platos The Republic for text generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1el5RnjHN7V8"
      },
      "source": [
        "import random"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSE76UtwpUuB",
        "outputId": "1d2c0e6c-30b1-4b2d-8f3f-6ce4c2ac32f3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "philosophers.ipynb  republic.txt  tao_train.txt     zarathustra_test.txt\n",
            "plato\t\t    runs\t  tao.txt\t    zarathustra_train.txt\n",
            "plato_eval\t    tao\t\t  transformers\t    zarathustra.txt\n",
            "republic_test.txt   tao_eval\t  zarathustra\n",
            "republic_train.txt  tao_test.txt  zarathustra_eval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk_dT91bbE6F",
        "outputId": "d7f8d025-cc18-4226-ec36-10138b1ca3aa"
      },
      "source": [
        "%cd drive/MyDrive/CuddleFish/transformer/563_project/philosophers"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/CuddleFish/transformer/563_project/philosophers'\n",
            "/content/drive/MyDrive/CuddleFish/transformer/563_project/philosophers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP2GBDMDtbSV",
        "outputId": "e17a37d8-c34f-4b18-9647-b1fc9d77706e"
      },
      "source": [
        "%%bash\n",
        "cd transformers\n",
        "pip install ."
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/drive/My Drive/CuddleFish/transformer/563_project/philosophers/transformers\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2020.12.5)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517): started\n",
            "  Building wheel for transformers (PEP 517): finished with status 'done'\n",
            "  Created wheel for transformers: filename=transformers-4.7.0.dev0-cp37-none-any.whl size=2354246 sha256=42a7faea3a89e6da84ac8b8209e67a9a99fe5bf60bfec1d79f904bc20c957eea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1rx5_gei/wheels/40/af/af/f0c3e93b186e2419c7db936d2b8fdffee00c3ffa4d0626f165\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 4.7.0.dev0\n",
            "    Uninstalling transformers-4.7.0.dev0:\n",
            "      Successfully uninstalled transformers-4.7.0.dev0\n",
            "Successfully installed transformers-4.7.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVuDKFJCqe7d",
        "outputId": "74be4076-a894-43a7-edf3-a25a429140c5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "philosophers.ipynb  republic.txt  tao_train.txt     zarathustra_test.txt\n",
            "plato\t\t    runs\t  tao.txt\t    zarathustra_train.txt\n",
            "plato_eval\t    tao\t\t  transformers\t    zarathustra.txt\n",
            "republic_test.txt   tao_eval\t  zarathustra\n",
            "republic_train.txt  tao_test.txt  zarathustra_eval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "843OokxatHCV",
        "outputId": "cf8a1fbe-446b-43f1-f086-74e66f6b431a"
      },
      "source": [
        "%%bash\n",
        "cd transformers/examples/pytorch/language-modeling\n",
        "ls"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "README.md\n",
            "requirements.txt\n",
            "run_clm_no_trainer.py\n",
            "run_clm.py\n",
            "run_mlm_no_trainer.py\n",
            "run_mlm.py\n",
            "run_plm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJGIJJShjFxy",
        "outputId": "f78fcb7a-ff5c-4846-ef99-738ee4149481"
      },
      "source": [
        "pip install -r transformers/examples/pytorch/language-modeling/requirements.txt"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (0.1.95)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2021.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (4.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (57.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVibxmJFoDdF",
        "outputId": "8336c183-3008-47a8-95ff-6a692bb5a4b5"
      },
      "source": [
        "!python transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_name_or_path plato \\\n",
        "    --train_file republic.txt \\\n",
        "    --do_train \\\n",
        "    --num_train_epochs 100 \\\n",
        "    --output_dir plato \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_steps 20000 \\\n",
        "    --per_gpu_train_batch_size 4"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 02:43:46.058509: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x7f79cd4d9290>\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 182, in cb\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"transformers/examples/pytorch/language-modeling/run_clm.py\", line 34, in <module>\n",
            "    from transformers import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1032, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\", line 2828, in __getattr__\n",
            "    return super().__getattr__(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 1855, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\", line 2822, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 38, in <module>\n",
            "    from .integrations import (  # isort: split\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/integrations.py\", line 45, in <module>\n",
            "    from .trainer_callback import TrainerCallback  # noqa: E402\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer_callback.py\", line 27, in <module>\n",
            "    from .trainer_utils import IntervalStrategy\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer_utils.py\", line 46, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/__init__.py\", line 48, in <module>\n",
            "    from tensorflow.python import keras\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/__init__.py\", line 25, in <module>\n",
            "    from tensorflow.python.keras import models\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/models.py\", line 20, in <module>\n",
            "    from tensorflow.python.keras import metrics as metrics_module\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\", line 37, in <module>\n",
            "    from tensorflow.python.keras import activations\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/activations.py\", line 18, in <module>\n",
            "    from tensorflow.python.keras.layers import advanced_activations\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/__init__.py\", line 22, in <module>\n",
            "    from tensorflow.python.keras.engine.input_layer import Input\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_layer.py\", line 24, in <module>\n",
            "    from tensorflow.python.keras.engine import base_layer\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 49, in <module>\n",
            "    from tensorflow.python.keras.engine import base_layer_utils\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\", line 31, in <module>\n",
            "    from tensorflow.python.keras.utils import tf_utils\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 22, in <module>\n",
            "    from tensorflow.python.distribute.coordinator import cluster_coordinator as coordinator_lib\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/coordinator/cluster_coordinator.py\", line 36, in <module>\n",
            "    from tensorflow.python.distribute import parameter_server_strategy_v2\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/parameter_server_strategy_v2.py\", line 33, in <module>\n",
            "    from tensorflow.python.distribute import parameter_server_strategy\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/parameter_server_strategy.py\", line 34, in <module>\n",
            "    from tensorflow.python.distribute.cluster_resolver import SimpleClusterResolver\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cluster_resolver/__init__.py\", line 31, in <module>\n",
            "    from tensorflow.python.distribute.cluster_resolver.gce_cluster_resolver import GCEClusterResolver\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py\", line 28, in <module>\n",
            "    from googleapiclient import discovery  # pylint: disable=g-import-not-at-top\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery.py\", line 38, in <module>\n",
            "    from email.mime.multipart import MIMEMultipart\n",
            "  File \"/usr/lib/python3.7/email/mime/multipart.py\", line 9, in <module>\n",
            "    from email.mime.base import MIMEBase\n",
            "  File \"/usr/lib/python3.7/email/mime/base.py\", line 9, in <module>\n",
            "    import email.policy\n",
            "  File \"/usr/lib/python3.7/email/policy.py\", line 9, in <module>\n",
            "    from email.headerregistry import HeaderRegistry as HeaderRegistry\n",
            "  File \"/usr/lib/python3.7/email/headerregistry.py\", line 14, in <module>\n",
            "    from email import _header_value_parser as parser\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 670, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 576, in module_from_spec\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tGPR37dsmbu",
        "outputId": "7a6a1808-fd72-48d2-ce6d-b7eb1b1d0802"
      },
      "source": [
        "!python transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_name_or_path zarathustra \\\n",
        "    --train_file zarathustra.txt \\\n",
        "    --do_train \\\n",
        "    --num_train_epochs 100 \\\n",
        "    --output_dir zarathustra \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_steps 20000 \\\n",
        "    --per_gpu_train_batch_size 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-08 17:15:08.171524: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/08/2021 17:15:09 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/08/2021 17:15:09 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=runs/Jun08_17-15-09_abc2956f4920,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=100.0,\n",
            "output_dir=zarathustra,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=zarathustra,\n",
            "save_steps=20000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "06/08/2021 17:15:10 - WARNING - datasets.builder -   Using custom data configuration default-cf9264b18e04ca67\n",
            "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-cf9264b18e04ca67/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-cf9264b18e04ca67/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "[INFO|configuration_utils.py:515] 2021-06-08 17:15:10,404 >> loading configuration file zarathustra/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-06-08 17:15:10,405 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"zarathustra\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:515] 2021-06-08 17:15:10,406 >> loading configuration file zarathustra/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-06-08 17:15:10,406 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"zarathustra\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1651] 2021-06-08 17:15:10,407 >> Didn't find file zarathustra/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:15:10,408 >> loading file zarathustra/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:15:10,408 >> loading file zarathustra/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:15:10,408 >> loading file zarathustra/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:15:10,408 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:15:10,408 >> loading file zarathustra/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:15:10,408 >> loading file zarathustra/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1153] 2021-06-08 17:15:11,503 >> loading weights file zarathustra/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1339] 2021-06-08 17:15:19,616 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-06-08 17:15:19,616 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at zarathustra.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "100% 14/14 [00:00<00:00, 50.47ba/s]\n",
            "100% 14/14 [00:00<00:00, 27.02ba/s]\n",
            "[WARNING|training_args.py:701] 2021-06-08 17:15:22,926 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:701] 2021-06-08 17:15:22,927 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:1147] 2021-06-08 17:15:22,928 >> ***** Running training *****\n",
            "[INFO|trainer.py:1148] 2021-06-08 17:15:22,928 >>   Num examples = 123\n",
            "[INFO|trainer.py:1149] 2021-06-08 17:15:22,928 >>   Num Epochs = 100\n",
            "[INFO|trainer.py:1150] 2021-06-08 17:15:22,928 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1151] 2021-06-08 17:15:22,928 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:1152] 2021-06-08 17:15:22,929 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1153] 2021-06-08 17:15:22,929 >>   Total optimization steps = 3100\n",
            "[WARNING|training_args.py:701] 2021-06-08 17:15:22,936 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "{'loss': 1.8397, 'learning_rate': 4.1935483870967746e-05, 'epoch': 16.13}\n",
            "{'loss': 1.2857, 'learning_rate': 3.387096774193548e-05, 'epoch': 32.26}\n",
            "{'loss': 0.9507, 'learning_rate': 2.5806451612903226e-05, 'epoch': 48.39}\n",
            "{'loss': 0.7386, 'learning_rate': 1.774193548387097e-05, 'epoch': 64.52}\n",
            "{'loss': 0.6155, 'learning_rate': 9.67741935483871e-06, 'epoch': 80.65}\n",
            "{'loss': 0.5513, 'learning_rate': 1.6129032258064516e-06, 'epoch': 96.77}\n",
            "100% 3100/3100 [23:49<00:00,  2.31it/s][INFO|trainer.py:1343] 2021-06-08 17:39:12,443 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1429.5218, 'train_samples_per_second': 8.604, 'train_steps_per_second': 2.169, 'train_loss': 0.9820827090355658, 'epoch': 100.0}\n",
            "100% 3100/3100 [23:49<00:00,  2.17it/s]\n",
            "[INFO|trainer.py:1887] 2021-06-08 17:39:12,455 >> Saving model checkpoint to zarathustra\n",
            "[INFO|configuration_utils.py:351] 2021-06-08 17:39:12,458 >> Configuration saved in zarathustra/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-06-08 17:39:13,521 >> Model weights saved in zarathustra/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-06-08 17:39:13,525 >> tokenizer config file saved in zarathustra/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-06-08 17:39:13,527 >> Special tokens file saved in zarathustra/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-08 17:39:14,547 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:39:14,547 >>   epoch                    =      100.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:39:14,547 >>   train_loss               =     0.9821\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:39:14,547 >>   train_runtime            = 0:23:49.52\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:39:14,547 >>   train_samples            =        123\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:39:14,547 >>   train_samples_per_second =      8.604\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:39:14,547 >>   train_steps_per_second   =      2.169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ortscMU7sm2z",
        "outputId": "ba336a87-8fa2-43f8-af16-ec9b16c8961d"
      },
      "source": [
        "!python transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_name_or_path tao \\\n",
        "    --train_file tao.txt \\\n",
        "    --do_train \\\n",
        "    --num_train_epochs 100 \\\n",
        "    --output_dir tao \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_steps 20000 \\\n",
        "    --per_gpu_train_batch_size 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-08 17:39:18.171886: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/08/2021 17:39:19 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/08/2021 17:39:19 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=runs/Jun08_17-39-19_abc2956f4920,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=100.0,\n",
            "output_dir=tao,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=tao,\n",
            "save_steps=20000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "06/08/2021 17:39:20 - WARNING - datasets.builder -   Using custom data configuration default-afb2cc9556fa84f1\n",
            "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-afb2cc9556fa84f1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-afb2cc9556fa84f1/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "[INFO|configuration_utils.py:515] 2021-06-08 17:39:20,317 >> loading configuration file tao/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-06-08 17:39:20,318 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"tao\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:515] 2021-06-08 17:39:20,319 >> loading configuration file tao/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-06-08 17:39:20,319 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"tao\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1651] 2021-06-08 17:39:20,320 >> Didn't find file tao/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:39:20,321 >> loading file tao/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:39:20,321 >> loading file tao/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:39:20,321 >> loading file tao/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:39:20,321 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:39:20,321 >> loading file tao/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-06-08 17:39:20,321 >> loading file tao/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1153] 2021-06-08 17:39:21,678 >> loading weights file tao/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1339] 2021-06-08 17:39:28,686 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-06-08 17:39:28,686 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at tao.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "100% 2/2 [00:00<00:00, 25.91ba/s]\n",
            "100% 2/2 [00:00<00:00, 37.47ba/s]\n",
            "[WARNING|training_args.py:701] 2021-06-08 17:39:31,315 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:701] 2021-06-08 17:39:31,316 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:1147] 2021-06-08 17:39:31,317 >> ***** Running training *****\n",
            "[INFO|trainer.py:1148] 2021-06-08 17:39:31,317 >>   Num examples = 13\n",
            "[INFO|trainer.py:1149] 2021-06-08 17:39:31,317 >>   Num Epochs = 100\n",
            "[INFO|trainer.py:1150] 2021-06-08 17:39:31,317 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1151] 2021-06-08 17:39:31,317 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:1152] 2021-06-08 17:39:31,317 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1153] 2021-06-08 17:39:31,317 >>   Total optimization steps = 400\n",
            "[WARNING|training_args.py:701] 2021-06-08 17:39:31,326 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "100% 400/400 [02:32<00:00,  3.00it/s][INFO|trainer.py:1343] 2021-06-08 17:42:03,873 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 152.5631, 'train_samples_per_second': 8.521, 'train_steps_per_second': 2.622, 'train_loss': 0.6007738494873047, 'epoch': 100.0}\n",
            "100% 400/400 [02:32<00:00,  2.62it/s]\n",
            "[INFO|trainer.py:1887] 2021-06-08 17:42:03,884 >> Saving model checkpoint to tao\n",
            "[INFO|configuration_utils.py:351] 2021-06-08 17:42:03,888 >> Configuration saved in tao/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-06-08 17:42:04,918 >> Model weights saved in tao/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-06-08 17:42:04,932 >> tokenizer config file saved in tao/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-06-08 17:42:04,936 >> Special tokens file saved in tao/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-08 17:42:05,895 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:42:05,895 >>   epoch                    =      100.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:42:05,895 >>   train_loss               =     0.6008\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:42:05,895 >>   train_runtime            = 0:02:32.56\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:42:05,895 >>   train_samples            =         13\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:42:05,895 >>   train_samples_per_second =      8.521\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-08 17:42:05,895 >>   train_steps_per_second   =      2.622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSdgzZFyhGO4",
        "outputId": "044545f2-83b6-450f-f702-bfa0e934e106"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=tao \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 100 \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/08/2021 04:00:08 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/08/2021 04:00:12 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=100, model_name_or_path='tao', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the nature of life?\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-08 04:00:29.703386: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the nature of life? He has no value in being what he does not have. When he has it, he is not guilty; when it does not, he is not free. Man is not free; when he has it, he is not free; when he has it, he is not free. So that the laws of man are as like a rule of law as before. Therefore, the different laws in his kingdom are as identical to those in every kingdom.26.2. Therefore, in the kingdom all\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the nature of life?›< *** I wish we could learn about this, but, why are you saying it to me when I am wrong? Therefore, when we are speaking the name of our heavenly Son, in his presence, we can see that the truth of life is still in full faith.So, I say, You are the one who is not disappointed with me, but at the same time makes it difficult for him to find the truth of his conduct, and thus makes him difficult to understand.Thus\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the nature of life? Will the consciousness allow this life to continue (as we call it?).\n",
            "But as far as the individual's desire and growth can go, how can the physical one remain open and active (in an atmosphere of exhaustion)? The physical state remains its purer nature; it remains its primitive state; and yet (it is) incapable of changing (the position of the movement). So what the allure of human thought does to the outside world and to the external world? It is the condition of constant\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the nature of life? Where, indeed, is the sun beneath and beneath us? And it is this way that allows them to live?1. Therefore how dare we go into the world, and it is what does not use it? Why cannot we rest in it?2. It is not by this that we can still have that beauty and simplicity, but when it comes to it, it becomes disgraceful and disgraceful.2. It is when these things are hidden to a certain degree, it is when we\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the nature of life?\n",
            "The ever-expanding implications of human activity and the unquantifiable nature of our movement must not be found in this way, and its work shall be not considered to be reproachful or unprofitable.\n",
            "19.                                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugjtkK9hxvaQ",
        "outputId": "2f4c7376-3677-4157-bf2e-f06b25955202"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=plato \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 150 \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/08/2021 18:29:12 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/08/2021 18:29:16 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=100, model_name_or_path='plato', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-08 18:29:21.647642: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning.But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case.You would agree with me in thinking that the State which we are describing is inanitions of the soul?Yes.And in that case the one has a natural good and noblenature; the other has a bad and useless nature?\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But why do you ask?Because you would not say that virtue is a virtue; for youwould. But I am sure that in the soul, as we are observing, a man maybe in a state of health when he is sick, and you would not say that virtue is a virtue.Yes, he said, I conceive that you are about to speak.And now what is that to him?What is that to him?I think, I said, that he who desires anything is\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning.But can the good be otherwise? Can he also be a lover of gain or loss,or a lover of honour or a lover of gain?Still he cannot refuse to take a turn at thecare of other men, or to disobey them in any important matter?He cannot.And so he goes on striving and railing against the unjust.Yes, he said, that is the nature of noble and humble andinvincible heroes.And what is the noble and humble nature relative to the truth and\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning.Yet, as we were saying before, we are not clearly saying that virtue is a virtue. And can you imagine any othersense in which a man is likely to behave rather than not asa vice?Impossible.Then, I said, there is no reason in thinking that the soul of a man is likely to be astrange being or a misfortune to him; to thinkthat this is the nature of temperance is to be found in him?Yes, he said, there is a\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning.But would you say that virtue is a good or noble thing--in either case, what is the nature of either?I should rather say that what he deems the good to be whatthe speaker deems the bad; but I would rather say that what is not the good is whatthe speaker deems the good; for you will not on the other handconsider the good what is not the good; and the just man will not thinkeither of the good and the unjust.Yes, he said, and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHcpdbdPfBQg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUTVyRE0fBOa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM2RQacKfBMD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w-gTS39fBHG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc59cbNwySSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf7bde5-6033-4e0e-a8e9-f34b8a1c75cc"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=plato \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 250 \\"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/10/2021 20:21:02 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/10/2021 20:21:07 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=250, model_name_or_path='plato', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case. He should beequivocal! at times, or, as I should imagine, at other times, at other times, his mind is buzzing with desire. Yes, he said, I have. Here, however, is the contradiction of time. He is the real object of his argument. He has no reason to speak, and therefore he is a hater; for theconclusion is required of the verbal truth. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. Thus, I said, the meaning of life is like the essentialtruth: when a man thinks himself to be free from envy andto hate and envy, then he is ready to commit the foulest murder; butat the same time, as you may imagine, he cannot commit the horrid murder. Yes, he said, that is the nature of the State; and the individual will notparticipate in the public execution of his crimes, because, as youwere saying, he is not in a state of rapture. Therefore the sage desires what people call 'the utmost degree of mystery.' Yes, I said, that is more thanlevel and harmony and plurality, and as the State is framed and educated, so is the soul of man.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-10 20:21:14.269986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case. He should beequivocal! at times, or, as I should imagine, at other times, at other times, his mind is buzzing with desire. Yes, he said, I have. Here, however, is the contradiction of time. He is the real object of his argument. He has no reason to speak, and therefore he is a hater; for theconclusion is required of the verbal truth. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. Thus, I said, the meaning of life is like the essentialtruth: when a man thinks himself to be free from envy andto hate and envy, then he is ready to commit the foulest murder; butat the same time, as you may imagine, he cannot commit the horrid murder. Yes, he said, that is the nature of the State; and the individual will notparticipate in the public execution of his crimes, because, as youwere saying, he is not in a state of rapture. Therefore the sage desires what people call 'the utmost degree of mystery.' Yes, I said, that is more thanlevel and harmony and plurality, and as the State is framed and educated, so is the soul of man.Yes, he said, that is what the dialectician will say.Yes, I said, he will; but you may suppose the opposite to be themeaning of the State in which the individual will commit the mostevil murder.I believe that you have quite conceived my meaning.I quite assent, he replied.Then let me ask you another question: By the ordinary dealings of men, is not thisthe sort of money that a father makes at the altar of the god?He is.And how is he to bring back the child from the evil mother, who is in a frenzy aboutthe theft of the carpenter's daughter, and especially the theft of the valetudinarian; also the theft of the helmet which he took from thedead body, and all the other valetudinarian burglars; also the theft of the helmet and all other valetudinarian burglars--these are some of the evils of which youwould only imagine him to have committed.And, I said, in the execution of his murder, the very meaningof the sentence is very clear:--He who committed the mostevil murder did so with the view to getting rid of the murderer'sdaughter; he was playing a fool\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case. He should beequivocal! at times, or, as I should imagine, at other times, at other times, his mind is buzzing with desire. Yes, he said, I have. Here, however, is the contradiction of time. He is the real object of his argument. He has no reason to speak, and therefore he is a hater; for theconclusion is required of the verbal truth. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. Thus, I said, the meaning of life is like the essentialtruth: when a man thinks himself to be free from envy andto hate and envy, then he is ready to commit the foulest murder; butat the same time, as you may imagine, he cannot commit the horrid murder. Yes, he said, that is the nature of the State; and the individual will notparticipate in the public execution of his crimes, because, as youwere saying, he is not in a state of rapture. Therefore the sage desires what people call 'the utmost degree of mystery.' Yes, I said, that is more thanlevel and harmony and plurality, and as the State is framed and educated, so is the soul of man.Yes, he said, the meaning of life may be further illustrated.He who consorts with slaves in foreign parts of the world may be calleda boaster, because he is a lover of money or honour; he can kill or eat beef, or be guilty of any other heinous act,which is not done, and therefore he is a simple idiot.Yes, he said, this is the meaning of a truly tragic orfavourite character; but there may be other respects in which a man may be misbehaved in another. He will bearer than he is, and will be the'most happy' man; he will be mad less than he is, andwill be less happy.Then who is truly happy is, in the strict sense of the term, who is the most miserable ofmen? Truth being what you term'most miserable,' you will say that heis.The class of women and children who are proposed to be their ministers;to whom they will be attached, and in turn must train in aselect class of men, who will be their ministers. The selection will be very one and a half;the preference will be given to our brave souls who are in themiddle of the city, in the\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case. He should beequivocal! at times, or, as I should imagine, at other times, at other times, his mind is buzzing with desire. Yes, he said, I have. Here, however, is the contradiction of time. He is the real object of his argument. He has no reason to speak, and therefore he is a hater; for theconclusion is required of the verbal truth. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. Thus, I said, the meaning of life is like the essentialtruth: when a man thinks himself to be free from envy andto hate and envy, then he is ready to commit the foulest murder; butat the same time, as you may imagine, he cannot commit the horrid murder. Yes, he said, that is the nature of the State; and the individual will notparticipate in the public execution of his crimes, because, as youwere saying, he is not in a state of rapture. Therefore the sage desires what people call 'the utmost degree of mystery.' Yes, I said, that is more thanlevel and harmony and plurality, and as the State is framed and educated, so is the soul of man.Yes, he said, that is what the individual desires.But do you suppose that, when he has committed the horrid murder, he will notdream of committing the foulest murder.He will. Now that which he wishes to commit is a mean orshameful which is not good; for the evil is what he desires; and this is he who would commit the unholy thingwhich is in the fullest vigour.Certainly, he said; and that which he wishes to commit is a mean orshameful which is not good.And therefore when he thinks that the manifold gifts of nature are great, and that the several parts only,the nature of each thing is great, and that each thing issmall, he will conceive that he is one, and not many.Yes, he said, that is true; and this is he who does the great work ofdestruction?Of course.Now when the manifold gifts of nature are adequately presented to the mind,they are mixed; they are many, as the words may be, and there are many more complex natures.Very true.But do you imagine that persons who are unable to see the absolutemeanness of each thing, and who cannot see the absolute truth\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case. He should beequivocal! at times, or, as I should imagine, at other times, at other times, his mind is buzzing with desire. Yes, he said, I have. Here, however, is the contradiction of time. He is the real object of his argument. He has no reason to speak, and therefore he is a hater; for theconclusion is required of the verbal truth. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. Thus, I said, the meaning of life is like the essentialtruth: when a man thinks himself to be free from envy andto hate and envy, then he is ready to commit the foulest murder; butat the same time, as you may imagine, he cannot commit the horrid murder. Yes, he said, that is the nature of the State; and the individual will notparticipate in the public execution of his crimes, because, as youwere saying, he is not in a state of rapture. Therefore the sage desires what people call 'the utmost degree of mystery.' Yes, I said, that is more thanlevel and harmony and plurality, and as the State is framed and educated, so is the soul of man.Yes, he said, that is also his meaning. But when the State has been made perfectlyadjusted, he cannot commit the horrid murder; he will not be in a state of rapture; he will be in aloose state of rapture.He cannot. But the motive which led the noble and spirited element tocommit the homicide was that which characteristically followed the noble principle; alsobecause the noble thought in the soul was unable to commit the horrid murder.Certainly.Therefore, my excellent friend, I said, we have been describing how Uranus, who is thebrother of Poseidon, Maintains peace withus, desires the return of thelover of Zeus, to his father, but, instead of returning to his father,Lover of Pamphylian, desires to have the body of the goddess restored.Thus united, he proceeds; but if he have the power, he cannot committhe horrid murder.Yes, he said, that is the only reasonable conclusion.Then, my friend, we have reason to think that Uranus, whois the son of Apollo, should be a friend and maintainer of the revolution; thereis reason in his soul to think that he can and will commit\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life? Does not the word express more than the fact? Then virtue is a virtue having a natural good and noble nature? 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Yes, he said, that is the meaning. But you see that the latter occurs only when a man is in a state of rapture,and that the rational principle which he assumes also has a natural good--in either case, as you mayimagine, he is not at all happy in either case. He should beequivocal! at times, or, as I should imagine, at other times, at other times, his mind is buzzing with desire. Yes, he said, I have. Here, however, is the contradiction of time. He is the real object of his argument. He has no reason to speak, and therefore he is a hater; for theconclusion is required of the verbal truth. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. Thus, I said, the meaning of life is like the essentialtruth: when a man thinks himself to be free from envy andto hate and envy, then he is ready to commit the foulest murder; butat the same time, as you may imagine, he cannot commit the horrid murder. Yes, he said, that is the nature of the State; and the individual will notparticipate in the public execution of his crimes, because, as youwere saying, he is not in a state of rapture. Therefore the sage desires what people call 'the utmost degree of mystery.' Yes, I said, that is more thanlevel and harmony and plurality, and as the State is framed and educated, so is the soul of man.Yes, he said, this is he who is seeking for truth.And must not the soul of man be like the State which we have now described?Certainly.He who is wanting in a State, whether male or female, will desire to have thegreatest share in the government of the State?Yes, he said, he will.And the State which he is seeking is like that of the individual: but he will notschedule, or allow the birth or education of his desired ones, because, as youwere saying, he is aiming at a primary form of government, and he will not win the popular vote in thegeneral popular vote.That is quite true, he said.The best and purest of political desires is the contentious or ambitious; for that is also themeaning of the whole state; and as I should imagine, many other matters are awaitinghis mind, which may, I think, be already discussed.Certainly, he said.In seeking to attain truth he must first have the power of estimating the value ofjustice; then he will measure the honour and glories, and the honour requiredby him.That is quite true, he said.The second object of his politics is the preservation of thehonour\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-grUBrxydJS",
        "outputId": "4aa46905-8ef7-48ac-a938-882624791ebe"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=tao \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 250 \\"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/10/2021 20:16:59 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/10/2021 20:17:04 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=250, model_name_or_path='tao', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life? By what reason? Because of their selfish desires. 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). He is straightforward about his issues, but does not condescend tothe people. He does not dare to (try to) act with an ulterior purpose. He should beequivocal! He should be straightforward about his issues, but does not dare to (try to) doanything. Or something (like this)   That might be called 'The mysterious Quality of the Tao.' Here, however, is the contradiction of time. Such questions arise from their havingsuch a deep andeterminable existence. Is it not because they did not come from man they who could design and conduct the world? Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. It is thus that the sage seeks what is highest and foremost his good; he seeks what islow, andtherefore he considers himself the foremost. 1. The Tao in its regular course does nothing (for the sake ofdoing it), and therefore there is nothing which it does not do. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-10 20:17:11.042153: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life? By what reason? Because of their selfish desires. 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). He is straightforward about his issues, but does not condescend tothe people. He does not dare to (try to) act with an ulterior purpose. He should beequivocal! He should be straightforward about his issues, but does not dare to (try to) doanything. Or something (like this)   That might be called 'The mysterious Quality of the Tao.' Here, however, is the contradiction of time. Such questions arise from their havingsuch a deep andeterminable existence. Is it not because they did not come from man they who could design and conduct the world? Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. It is thus that the sage seeks what is highest and foremost his good; he seeks what islow, andtherefore he considers himself the foremost. 1. The Tao in its regular course does nothing (for the sake ofdoing it), and therefore there is nothing which it does not do. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.2. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.  Therefore the sage seeks what people call 'the utmost degree of mystery.'The difficulty in governing a state by one man's will is that of his own;this is what ismeant by what he puts forward.3. Therefore the sage desires what people call 'the utmost degree of mystery.' The partial of knowledge that men present in the room consider istheir utmost degree of mystery.  If this partial(source of)knowledge were known, for what reason?  This partial(source of)knowledge would seem equally true to all men, but I would so order it that it benevermultiplication.4. Therefore the sage desires what men do not desire, but (find) men who do not desire men who do not desire them, and men who do not wish to be (at the behest of)themselves, and men who do not wish to be (at the behest of)themselves.  This partial of knowledgewould seem equally true to all men, but I wouldso order it that\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life? By what reason? Because of their selfish desires. 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). He is straightforward about his issues, but does not condescend tothe people. He does not dare to (try to) act with an ulterior purpose. He should beequivocal! He should be straightforward about his issues, but does not dare to (try to) doanything. Or something (like this)   That might be called 'The mysterious Quality of the Tao.' Here, however, is the contradiction of time. Such questions arise from their havingsuch a deep andeterminable existence. Is it not because they did not come from man they who could design and conduct the world? Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. It is thus that the sage seeks what is highest and foremost his good; he seeks what islow, andtherefore he considers himself the foremost. 1. The Tao in its regular course does nothing (for the sake ofdoing it), and therefore there is nothing which it does not do. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.2. But I do not know whose son it is.  If one take the foremostplace, and the other take the lead, I see that he is the son of the few; he who takes the lead in all things is the son of few; and in thesequence of great calamities(of his will).3. Therefore a sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will is that of his own;this is what ismeant by what he puts forward.4. He who possesses the mother of the state may in the same way beemployed to govern a state by one man'swill; he who occupies the mother of the state may in the same way beemployed to govern a state by one man'swill; he who occupies the mother of the state may in the same way beemployed to govern a state by one man's will; he who occupies the mother of the state may in the same way beemployed to govern a state by one man's will; and in thesequence of great calamities(of his will).6. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life? By what reason? Because of their selfish desires. 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). He is straightforward about his issues, but does not condescend tothe people. He does not dare to (try to) act with an ulterior purpose. He should beequivocal! He should be straightforward about his issues, but does not dare to (try to) doanything. Or something (like this)   That might be called 'The mysterious Quality of the Tao.' Here, however, is the contradiction of time. Such questions arise from their havingsuch a deep andeterminable existence. Is it not because they did not come from man they who could design and conduct the world? Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. It is thus that the sage seeks what is highest and foremost his good; he seeks what islow, andtherefore he considers himself the foremost. 1. The Tao in its regular course does nothing (for the sake ofdoing it), and therefore there is nothing which it does not do. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.2. The sage puts his own person last, and therefore he lasters; he puts his own person last, and therefore he lasters; and therefore he lasters; and thus he lasters;and thus he lasters; and thus he lasters;and thus he lasters; and thus he lasters;and thus he lasters;and thus he lasters;and thus he lasters;and thus he lasters;and thus he lasters;and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters;and thus he lasters; and thus he lasters;and thus he lasters; and thus he lasters; and thus he lasters;and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters;and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters;and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters; and thus he lasters\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life? By what reason? Because of their selfish desires. 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). He is straightforward about his issues, but does not condescend tothe people. He does not dare to (try to) act with an ulterior purpose. He should beequivocal! He should be straightforward about his issues, but does not dare to (try to) doanything. Or something (like this)   That might be called 'The mysterious Quality of the Tao.' Here, however, is the contradiction of time. Such questions arise from their havingsuch a deep andeterminable existence. Is it not because they did not come from man they who could design and conduct the world? Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. It is thus that the sage seeks what is highest and foremost his good; he seeks what islow, andtherefore he considers himself the foremost. 1. The Tao in its regular course does nothing (for the sake ofdoing it), and therefore there is nothing which it does not do. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.2. Thus it is that the sage desires what the people call 'the utmost degree of mystery.'  How do I know that it is so with all the beauties of the Tao?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?   By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason?  By what reason? \n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life? By what reason? Because of their selfish desires. 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). He is straightforward about his issues, but does not condescend tothe people. He does not dare to (try to) act with an ulterior purpose. He should beequivocal! He should be straightforward about his issues, but does not dare to (try to) doanything. Or something (like this)   That might be called 'The mysterious Quality of the Tao.' Here, however, is the contradiction of time. Such questions arise from their havingsuch a deep andeterminable existence. Is it not because they did not come from man they who could design and conduct the world? Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. It is thus that the sage seeks what is highest and foremost his good; he seeks what islow, andtherefore he considers himself the foremost. 1. The Tao in its regular course does nothing (for the sake ofdoing it), and therefore there is nothing which it does not do. Therefore the sage desires what people call 'the utmost degree of mystery.' The difficulty in governing a state by one man's will isthat of his own;this is what ismeant by what he puts forward.2. The difficulty in governing a state by one man's will is that of his own;this is what ismeant by what he puts forward.  Therefore a sage desires what people call 'the utmost degree of mystery.'   The difficulty in governing a state by one man's will is that of his own; this is what ismeant by what he puts forward.3. Therefore the sage desires what people call 'the utmost degree of mystery.'   Therefore the sage seeks what people call 'the utmost degree of mystery.'   Therefore the sage desires what people call 'the utmost degree of mystery.'   Therefore the sage seeks what people call 'the utmost degree of mystery.'   Therefore the sage seeks what people call 'the utmost degree of mystery.'4. Therefore the sage desires what people call 'the utmost degree of mystery.'  Thus he puts forward legislation,justice, and great calamity.  Itis through his not making himself victorious, but rather his having his place before the people.3. Therefore a sage has his place before them all, and he does not dareto act (with an ulterior purpose).  He has his place before them all, and he does not dareto act (\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtf84ozjyWCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab684cd0-9370-4eb6-98b3-0d74a2b99623"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=zarathustra \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 250 \\"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/10/2021 20:18:36 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/10/2021 20:18:40 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=250, model_name_or_path='zarathustra', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life? What is deep and unsettled and dangerous? And if there be life which doth not impel you, see me troubled, drivenforth, with the will of they bowels! 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Here, however, Zarathustra calleth it virtue to speak otherwise:--What wisdom should Zarathustra think if he had to bowels! And if he should have those kine carried it, well! He should beequivocal! He is equivocal! He is impervious to pain. Here, however, is the contradiction of time. He already have thathalcyon, and his eyes do not see anything. He already hastened this folly. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. He is not a poet; his eye doth not see anything, and it cannot seeanything. Here, however, is Zarathustra’s heart: and all the thoughts in his mouth are voluptuous andsultry. Therefore the sage desires what people call 'the utmost degree of mystery.' EREOF is all knowledge hitherto.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-10 20:18:47.165684: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life? What is deep and unsettled and dangerous? And if there be life which doth not impel you, see me troubled, drivenforth, with the will of they bowels! 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Here, however, Zarathustra calleth it virtue to speak otherwise:--What wisdom should Zarathustra think if he had to bowels! And if he should have those kine carried it, well! He should beequivocal! He is equivocal! He is impervious to pain. Here, however, is the contradiction of time. He already have thathalcyon, and his eyes do not see anything. He already hastened this folly. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. He is not a poet; his eye doth not see anything, and it cannot seeanything. Here, however, is Zarathustra’s heart: and all the thoughts in his mouth are voluptuous andsultry. Therefore the sage desires what people call 'the utmost degree of mystery.' EREOF is all knowledge hitherto. He is of the populace in which a measure is made.He can speak in a sensible way; but the peopleare wont to believe him. Thepopulace, however, and the populace, however, seem to him theonly people who fall into his way,--all the kine.Him who is of a sound mind, and much unconscious wisdom--there seemeth amuteness in all things. Culture, however, is a thing. Culture,however, a thing. He is a scholar, and much ignorance. Here,however, there seemeth a great gap, so that the people keep him out of their ears.An attempt by a people to teach him sense, and I do not think thathe can understand them. He cannot even understand everything, and hath notreason enough to know it.Him who is of a sound mind, could not even grasp at all the wholesome thoughts that are in his mouth. Culture, however, is asort of sense. He is an ass. He is also a poet. If the people will not understand him, how could they divine that everything they offer him isinterpreted, and changeable, and evaluing man withinterpretable blind eyes.\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life? What is deep and unsettled and dangerous? And if there be life which doth not impel you, see me troubled, drivenforth, with the will of they bowels! 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Here, however, Zarathustra calleth it virtue to speak otherwise:--What wisdom should Zarathustra think if he had to bowels! And if he should have those kine carried it, well! He should beequivocal! He is equivocal! He is impervious to pain. Here, however, is the contradiction of time. He already have thathalcyon, and his eyes do not see anything. He already hastened this folly. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. He is not a poet; his eye doth not see anything, and it cannot seeanything. Here, however, is Zarathustra’s heart: and all the thoughts in his mouth are voluptuous andsultry. Therefore the sage desires what people call 'the utmost degree of mystery.' EREOF is all knowledge hitherto. BEFORE THE GREAT DEATH there is nothing newand nothing new. And also not evenrings or dice or dice-calls are still in existence.Thus spake Zarathustra.VI. OUT OF SERVICE.The fortress of Death, built in Nineveh, is now called “The Pitiful.” But the people say there are other names,such as “The OneGod” and “The Two-Spirit”; but even the peoplestill confoundeth their doctrines with those who call themselves the good and just. These are their greatestwords, their little words sagacity.Before the ugliest man cometh, then do their words conspired andfooledwith cunning jests. Then do their words mortify and make the heartsick of their lust.And much secret, verily, is still possible with those words oflove. Love itself hath the devil in most people; italways cackleth because it findeth soft lustreth. And not only doth the devil find it.Much secret hath there been in the world, that it cannot find pleasure or pleasureeither. And not every one, however, believeth in seeing pleasure.Even those who preach\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life? What is deep and unsettled and dangerous? And if there be life which doth not impel you, see me troubled, drivenforth, with the will of they bowels! 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Here, however, Zarathustra calleth it virtue to speak otherwise:--What wisdom should Zarathustra think if he had to bowels! And if he should have those kine carried it, well! He should beequivocal! He is equivocal! He is impervious to pain. Here, however, is the contradiction of time. He already have thathalcyon, and his eyes do not see anything. He already hastened this folly. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. He is not a poet; his eye doth not see anything, and it cannot seeanything. Here, however, is Zarathustra’s heart: and all the thoughts in his mouth are voluptuous andsultry. Therefore the sage desires what people call 'the utmost degree of mystery.' EREOF is all knowledge hitherto. BEFORE THE TRUTH is knowledge hitherto! Thishath hitherto been the man’s best knowledge; and only BEFORE the lion hath laid its eggs. BEFORE the serpent hath laid its eggs, man hath thoroughly understood man’s world.THIS CONSCIENTIOUS WISE: FROM THE HIGHER MAN GRIEF OF THE HIGHER MAN. BEFORE the serpent hath laid its eggs, man hath thoroughly understood man’s world.THIS CONSCIENTIOUS WISE: FROM THE HIGHER MAN GRIEF OF THE HIGHER MAN.Somewhere do I now sit, and ask myself: What hath hitherto been the greatest folly in man? What hath hitherto been the greatest folly in man?--THE SPIRIT OF THE MAN: FROM THE HIGHER MAN GRIEF OF THE HIGHER MAN.TO ME THE HIGHER MAN: That is the depth of the man.Let him be silent, thou overslept child; for that is the depth of the man. And he who is silent, wilt thou have cause for great distress.”--Thus spake Zarathustra.XLVIII. THE BITE OF THE ADDER.Ye do\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life? What is deep and unsettled and dangerous? And if there be life which doth not impel you, see me troubled, drivenforth, with the will of they bowels! 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Here, however, Zarathustra calleth it virtue to speak otherwise:--What wisdom should Zarathustra think if he had to bowels! And if he should have those kine carried it, well! He should beequivocal! He is equivocal! He is impervious to pain. Here, however, is the contradiction of time. He already have thathalcyon, and his eyes do not see anything. He already hastened this folly. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. He is not a poet; his eye doth not see anything, and it cannot seeanything. Here, however, is Zarathustra’s heart: and all the thoughts in his mouth are voluptuous andsultry. Therefore the sage desires what people call 'the utmost degree of mystery.' EREOF is all knowledge hitherto. Only the madness of the intellect might put Zarathustraabove it.He may well be a poet. But it is the madness of the bowels of the intellect--thereof can one day be emancipated. Thus is the madness of the soul.Thus spake Zarathustra.LVIII. THE AWAKENING.When Zarathustra so spake, his animals ran away from him. And already had theyhind scattered and scattered also his thoughts. Then the animals ran away from him. And already had theyhind scattered also his thoughts. Then they became calm andliving.Everything as if it had been round or by-path, or by-path; things only doeth sense, and sense. But sense is a simile, and there is alsoan intoxicating pleasure.Here Zarathustra preached prudence and prudence.Confusion of good and evil--these are the three best devils in the world. They are both good and evil,through them delight; they want merely their longings--and they want merely their very good.Confusion of good and evil--these are the three best devils in the world. They are all at once evil and dangerous. Confusion\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life? What is deep and unsettled and dangerous? And if there be life which doth not impel you, see me troubled, drivenforth, with the will of they bowels! 2. Therefore the sage desires what he does not desire, but doesnot dareto act (with an ulterior purpose). Here, however, Zarathustra calleth it virtue to speak otherwise:--What wisdom should Zarathustra think if he had to bowels! And if he should have those kine carried it, well! He should beequivocal! He is equivocal! He is impervious to pain. Here, however, is the contradiction of time. He already have thathalcyon, and his eyes do not see anything. He already hastened this folly. Yes, I said; and yet he is conscious that he is a hater; the truth is, and he will say that,unless he be a philosopher, he will not have the natural feeling of hisdesire. He is not a poet; his eye doth not see anything, and it cannot seeanything. Here, however, is Zarathustra’s heart: and all the thoughts in his mouth are voluptuous andsultry. Therefore the sage desires what people call 'the utmost degree of mystery.' EREOF is all knowledge hitherto. Now, however, doth Zarathustra mean to speak otherwise:--Ere Zarathustra calleth his doctrine of time. Now, however, doth he become conscious ofits danger and fall!That he can no longer love his loved ones, his great love doth not mean to love them, itis a blunder in his heart. For thee doeth he here, the greatest dangermatter to the highest man, and a blunder in his heart.At his enemies, there is great longing for truth; and as greata danger as thegreat danger, doth he here say: “Where is there truth? Where is there will?” But here itis plain to me what the greatest danger can do. Doth he here mean to love his enemies?He who hath subdued monsters, hath solved all monsters; doth he here mean to slay, andto drive mad beasts into the valleys. But here thegreat Dane calleth it his evil, that he can no longer love his loved ones.Hath not the devil in his heart now been able to grasp at the smallest contradiction in his heart? This, however, is the danger of the highest man: WHAT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X98Y3RU7e9FQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFrsx_-e9Cy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6mGE3Dye9Ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh2SsN6Qe8-H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79f8E5-je873"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y49-cPJvPNOh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExhsWlGrtnSp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k7WF4zVtnQX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE1hpnhLtnOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "928PPXHRtoXz"
      },
      "source": [
        "# Train with Eval (for Perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLTuxwn6JEy"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEAIQXpv6K-5",
        "outputId": "3ef2e929-2b8d-439d-e19a-49ddea990e4d"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_FgBY1gA6q8"
      },
      "source": [
        "# TAO EVAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kmpEQsr5lST"
      },
      "source": [
        "Cross-validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On1rJOEbKk24",
        "outputId": "380a6cdd-9aa5-4d06-a9d6-da8be4f53975"
      },
      "source": [
        "dataset_file = 'tao.txt'\n",
        "train_set_file = \"tao_train.txt\"\n",
        "val_set_file = \"tao_test.txt\"\n",
        "with open(dataset_file) as dataset_wrapper:\n",
        "  val_split = 0.2\n",
        "  dataset = dataset_wrapper.read()\n",
        "  len_dataset = len(dataset)\n",
        "  randint = random.randint(0,4)\n",
        "  print(randint)\n",
        "  val_start = int(len_dataset * val_split * randint)\n",
        "  val_end = int(len_dataset * val_split * (randint+1))\n",
        "  print(val_start)\n",
        "  print(val_end)\n",
        "  train_set = dataset[:val_start] + dataset[val_end:]\n",
        "  val_set = dataset[val_start:val_end]\n",
        "  print(len(train_set))\n",
        "  print(len(val_set))\n",
        "with open(train_set_file, 'w') as writer_train:\n",
        "    writer_train.write(train_set)\n",
        "with open(val_set_file, 'w') as writer_val:\n",
        "    writer_val.write(val_set)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "35393\n",
            "47191\n",
            "47191\n",
            "11798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkylQ7DktnMH",
        "outputId": "a690d4a3-ce78-4a8d-d5ea-5855527657fc"
      },
      "source": [
        "!python transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=distilgpt2 \\\n",
        "    --do_train \\\n",
        "    --train_file=tao_train.txt \\\n",
        "    --do_eval \\\n",
        "    --validation_file=tao_test.txt \\\n",
        "    --num_train_epochs 40 \\\n",
        "    --output_dir tao_eval \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_steps 20000 \\\n",
        "    --per_device_train_batch_size 4"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 18:14:44.994736: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/10/2021 18:14:46 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/10/2021 18:14:46 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=runs/Jun10_18-14-46_d80cbc6d5d47,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=40.0,\n",
            "output_dir=tao_eval,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=4,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=tao_eval,\n",
            "save_steps=20000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "06/10/2021 18:14:46 - WARNING - datasets.builder -   Using custom data configuration default-b605ad9d8fef9c0b\n",
            "06/10/2021 18:14:46 - WARNING - datasets.builder -   Reusing dataset text (/root/.cache/huggingface/datasets/text/default-b605ad9d8fef9c0b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "[INFO|configuration_utils.py:517] 2021-06-10 18:14:47,195 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "[INFO|configuration_utils.py:553] 2021-06-10 18:14:47,196 >> Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:517] 2021-06-10 18:14:47,299 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "[INFO|configuration_utils.py:553] 2021-06-10 18:14:47,299 >> Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:14:47,915 >> loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:14:47,915 >> loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:14:47,915 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:14:47,915 >> loading file https://huggingface.co/distilgpt2/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:14:47,915 >> loading file https://huggingface.co/distilgpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:14:47,915 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|modeling_utils.py:1155] 2021-06-10 18:14:48,090 >> loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
            "[INFO|modeling_utils.py:1339] 2021-06-10 18:14:49,660 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-06-10 18:14:49,660 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "06/10/2021 18:14:49 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-b605ad9d8fef9c0b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-3c96b3d44cdd68cb.arrow\n",
            "06/10/2021 18:14:49 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-b605ad9d8fef9c0b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-83c8a08386699ba5.arrow\n",
            "06/10/2021 18:14:49 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-b605ad9d8fef9c0b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-11abbbd762ec7877.arrow\n",
            "06/10/2021 18:14:49 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-b605ad9d8fef9c0b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-a2adf8fff088d615.arrow\n",
            "[INFO|trainer.py:1147] 2021-06-10 18:14:52,307 >> ***** Running training *****\n",
            "[INFO|trainer.py:1148] 2021-06-10 18:14:52,307 >>   Num examples = 10\n",
            "[INFO|trainer.py:1149] 2021-06-10 18:14:52,307 >>   Num Epochs = 40\n",
            "[INFO|trainer.py:1150] 2021-06-10 18:14:52,308 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:1151] 2021-06-10 18:14:52,308 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:1152] 2021-06-10 18:14:52,308 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1153] 2021-06-10 18:14:52,308 >>   Total optimization steps = 120\n",
            "100% 120/120 [00:47<00:00,  2.73it/s][INFO|trainer.py:1343] 2021-06-10 18:15:39,581 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 47.2772, 'train_samples_per_second': 8.461, 'train_steps_per_second': 2.538, 'train_loss': 3.0216440836588543, 'epoch': 40.0}\n",
            "100% 120/120 [00:47<00:00,  2.54it/s]\n",
            "[INFO|trainer.py:1887] 2021-06-10 18:15:39,590 >> Saving model checkpoint to tao_eval\n",
            "[INFO|configuration_utils.py:351] 2021-06-10 18:15:39,594 >> Configuration saved in tao_eval/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-06-10 18:15:40,750 >> Model weights saved in tao_eval/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-06-10 18:15:40,754 >> tokenizer config file saved in tao_eval/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-06-10 18:15:40,758 >> Special tokens file saved in tao_eval/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-10 18:15:40,881 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,881 >>   epoch                    =       40.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,881 >>   train_loss               =     3.0216\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,882 >>   train_runtime            = 0:00:47.27\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,882 >>   train_samples            =         10\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,882 >>   train_samples_per_second =      8.461\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,882 >>   train_steps_per_second   =      2.538\n",
            "06/10/2021 18:15:40 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:2133] 2021-06-10 18:15:40,901 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2135] 2021-06-10 18:15:40,901 >>   Num examples = 2\n",
            "[INFO|trainer.py:2138] 2021-06-10 18:15:40,901 >>   Batch size = 8\n",
            "100% 1/1 [00:00<00:00, 13.07it/s]\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-10 18:15:40,992 >> ***** eval metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   epoch                   =       40.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   eval_loss               =      4.098\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   eval_runtime            = 0:00:00.08\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   eval_samples            =          2\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   eval_samples_per_second =      23.32\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   eval_steps_per_second   =      11.66\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:15:40,992 >>   perplexity              =    60.2209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FKF4PQutnhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48dfb291-7730-4e41-a73a-ff6f04fb9ff5"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=tao_eval \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 150 \\"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/10/2021 18:16:32 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/10/2021 18:16:37 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=150, model_name_or_path='tao_eval', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life?\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-10 18:16:46.614103: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life? Heavens come to earth, and cannot be fated to come back from it?But on the one hand, the Mother loves him.On the other hand, he loves men; on the other, he loves them.But on the other hand, he loves them.On the other hand, the Mother loves men; on the other, he loves them.And yet he loves them. And yet he does not flatter the sky; nor do he fail the earth; nor does he end the Earth.Those who are unhappy in life are rather than happy in life; those who are discontented in life are rather than content with it.But on the other hand, what is worth pursuing is worth pursuing.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life?› Of course not.But when we grasp the mysteries of man we become careless and fornot wishing to know them, we cannot see them.So what does it mean to be evil with no purpose or purpose? (But that is not to be said of men who do not like to be evil with no purpose or purpose.)But what if men do not like to be good with eachother?› Therefore we (desire to be at least one) should strive with eachother;what if they do not like to be at least one)?What if we strive so as to enlighten people by showing them the secrets of man?What if we strive so as to enlighten people by showing them the mysteries of man?(But\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life? (The word is not properly understood as (perceived) means), and thus there are ways of seeing and to see. 1. The idea of being in one's position is not (rightly) called (overlooked). (2. There are) ways of seeing (appear to be) invisible or invisible. (3. All things come from one's having what it takes to be human) 1. In truth it is not difficult to be (overlooked).2. (The way in which these two streams of knowledge arise is paradoxical; they flow from one's having what it takes to be human). What (comes from) is not found; what (comes from) is (always) thereby it.\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life? Wherever I am, when it does arise, I shall make it not yet known.27.2. 1. Do not know what is in your mouth, and when it is not on you I will not escape.2. If it is not in your mouth, I will not leave you alone.2. So he who has not spoken is sure; he who has not spoken is sure; he who has not spoken is sure; he who has not spoken is sure; he who has not spoken is sure; and yet he has not spoken is sure; yet he has not spoken is sure; yet he has not spoken is sure; yet he has not spoken is sure; yet he has not spoken is sure; yet he has not\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life?\n",
            "The simple fact is, the matter is, so when we look at it, we see the depth and brightness. Thus it seems to me that we should not be looking to repose by the door; that we should be making progress by the door. (This is how it is called.) (Thus it is called.) (Thus it is called.) (Thus it is called.) (Thus it is called.) (Thus it is called.) (Thus it is called.) (Thus it is called.) (So it is called.) (So it is called.) (So it is called.) (So it is called.) (So it is called.) (So it is called.) (So it is called.) (So it is called.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciOCfhiE2dg1"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=tao_eval \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 150 \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjhKybRaA3Qe",
        "outputId": "b1714f6d-7163-4059-969e-8ffbb3832340"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=plato_eval \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 150 \\"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/10/2021 16:09:49 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/10/2021 16:09:54 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=150, model_name_or_path='plato_eval', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life?\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-10 16:10:02.076358: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life?Does life have meaning or place in any particular State, affecting the ordering or controlling of the processes of man, animal,animal, State, and all other things?It has no place in the definition of life.Certainly not.Then a State may be absolutely free from the enslavement of women andchildren, and without the brutal and unusual forms of slavery--in which case the slave or slave is compelled to dothe like and do the like in almost everything; and may be perfectly furnished for the best ofall things, excepting all other miseries andfears and intemperance?Yes, he said, the true definition is also very clear.Yes, I said, and every other State will.But if so, we may\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life?Does life involve anything else or nothing else?It depends on the circumstances.Suppose you are in the city, have you no business, or are you in the city trying to find a husbandman or carpenter from where you are?If not, you will be in poverty. Will they not help you?I am speaking of poverty.And poverty does not consider the origin of poverty.But suppose the saying is not so easily taken out of the question: Will any one in your condition help or assist you in making the purchase or sale of ahorse--that is what you mean?The horseman or carpenter will assist you in making the purchase or sale of ahorse; but if he fails he will not be in poverty.I\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life?Does life have meaning or place in the human soul, inthat case, and in what case?Of the soul, he replied.And must not the body be a body?Certainly.And human life is the soul which we have delineated, and which is not to be defined, and which isnot to be confused with art and law?There is the art of medicine; art is art also concerned withdiscord and distraction, and that disorder and distraction arethe necessary sort ofthing; and we have given the general character of the soul tome and known persons as diseased persons.I think so too, he replied.Well, and is not life the truer sort of meaning?What do you mean? I mean that all\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life?Does life involve more or less of the other elements of nature, such as houses,ingress, and any other natural and acquired good?Yes, he said: life does not consider either the essential (naturaland acquired) or the acquired evil; and this is clearly the casewhen we take the business of agoravel, and define the term'mine' in your precise sense; and put the term'mine' in your precise sense.Yes, I said, the meaning is most perfectly clear.I do not mean to say that all things are somehow or othertravailable, or that the acquirement of them is somehow or othertravailable, or that they are all of one thing only, or that they all\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life?Does life have meaning or place in the human soul, inasmuch as life is more or less pure and simple?Of course, he replied.And surely the good and wise will not be affected by this or the other bad influences which maybe the cause of their natures being undermined?This is inconceivable.Then, if wealth and strength ever determine the ordering and happiness of the soul, how will theworld be governed if we only see a smallclass of goods which are not in their way?How can we rightly answer that question?What can there be? he replied.Thus much for the wise and good will be found out when we know that theworld is a one and the same;and this is what true rulers and subjects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTqABV8Nr7wl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hlfPvSpr7uN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgC3RSzwr7sC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfUCSUXZr7p0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4cVsujvr7nY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTcKYRnyA3OW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1AuCsuVA86M"
      },
      "source": [
        "#ZARATHUSTRA EVAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO2NqnjkA3Lr",
        "outputId": "163d6102-20c7-43e5-9f1e-ceb41d99030b"
      },
      "source": [
        ""
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "102906\n",
            "205813\n",
            "411627\n",
            "102907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg25EhbPMdUA",
        "outputId": "c9ef409b-e65d-41bf-b95c-37ecddc0d30f"
      },
      "source": [
        "dataset_file = 'zarathustra.txt'\n",
        "train_set_file = \"zarathustra_train.txt\"\n",
        "val_set_file = \"zarathustra_test.txt\"\n",
        "with open(dataset_file) as dataset_wrapper:\n",
        "  val_split = 0.2\n",
        "  dataset = dataset_wrapper.read()\n",
        "  len_dataset = len(dataset)\n",
        "  randint = random.randint(0,4)\n",
        "  print(randint)\n",
        "  val_start = int(len_dataset * val_split * randint)\n",
        "  val_end = int(len_dataset * val_split * (randint+1))\n",
        "  print(val_start)\n",
        "  print(val_end)\n",
        "  train_set = dataset[:val_start] + dataset[val_end:]\n",
        "  val_set = dataset[val_start:val_end]\n",
        "  print(len(train_set))\n",
        "  print(len(val_set))\n",
        "with open(train_set_file, 'w') as writer_train:\n",
        "    writer_train.write(train_set)\n",
        "with open(val_set_file, 'w') as writer_val:\n",
        "    writer_val.write(val_set)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "205813\n",
            "308720\n",
            "411627\n",
            "102907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKkqrVe7A3Ja",
        "outputId": "1150893e-42f7-418b-b3d2-2d223fc47383"
      },
      "source": [
        "!python transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=distilgpt2 \\\n",
        "    --do_train \\\n",
        "    --train_file=zarathustra_train.txt \\\n",
        "    --do_eval \\\n",
        "    --validation_file=zarathustra_test.txt \\\n",
        "    --num_train_epochs 15 \\\n",
        "    --output_dir zarathustra_eval \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_steps 20000 \\\n",
        "    --per_device_train_batch_size 4"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 18:31:33.939977: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/10/2021 18:31:35 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/10/2021 18:31:35 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=runs/Jun10_18-31-35_d80cbc6d5d47,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=15.0,\n",
            "output_dir=zarathustra_eval,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=4,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=zarathustra_eval,\n",
            "save_steps=20000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "06/10/2021 18:31:36 - WARNING - datasets.builder -   Using custom data configuration default-4ecf34f117037224\n",
            "06/10/2021 18:31:36 - WARNING - datasets.builder -   Reusing dataset text (/root/.cache/huggingface/datasets/text/default-4ecf34f117037224/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "[INFO|configuration_utils.py:517] 2021-06-10 18:31:36,249 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "[INFO|configuration_utils.py:553] 2021-06-10 18:31:36,250 >> Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:517] 2021-06-10 18:31:36,318 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "[INFO|configuration_utils.py:553] 2021-06-10 18:31:36,318 >> Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:31:36,725 >> loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:31:36,726 >> loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:31:36,726 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:31:36,726 >> loading file https://huggingface.co/distilgpt2/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:31:36,726 >> loading file https://huggingface.co/distilgpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:31:36,726 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|modeling_utils.py:1155] 2021-06-10 18:31:36,865 >> loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
            "[INFO|modeling_utils.py:1339] 2021-06-10 18:31:38,478 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-06-10 18:31:38,478 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "06/10/2021 18:31:38 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-4ecf34f117037224/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-af79b0650fcf9008.arrow\n",
            "06/10/2021 18:31:38 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-4ecf34f117037224/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-68f50beebc105a40.arrow\n",
            "06/10/2021 18:31:38 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-4ecf34f117037224/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-3abb244475ef63e2.arrow\n",
            "06/10/2021 18:31:38 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-4ecf34f117037224/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-d9c7fa8b9bf415b2.arrow\n",
            "[INFO|trainer.py:1147] 2021-06-10 18:31:41,182 >> ***** Running training *****\n",
            "[INFO|trainer.py:1148] 2021-06-10 18:31:41,182 >>   Num examples = 100\n",
            "[INFO|trainer.py:1149] 2021-06-10 18:31:41,182 >>   Num Epochs = 15\n",
            "[INFO|trainer.py:1150] 2021-06-10 18:31:41,182 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:1151] 2021-06-10 18:31:41,182 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:1152] 2021-06-10 18:31:41,182 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1153] 2021-06-10 18:31:41,182 >>   Total optimization steps = 375\n",
            "100% 375/375 [02:56<00:00,  2.13it/s][INFO|trainer.py:1343] 2021-06-10 18:34:37,287 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 176.1085, 'train_samples_per_second': 8.517, 'train_steps_per_second': 2.129, 'train_loss': 3.7737115885416666, 'epoch': 15.0}\n",
            "100% 375/375 [02:56<00:00,  2.13it/s]\n",
            "[INFO|trainer.py:1887] 2021-06-10 18:34:37,296 >> Saving model checkpoint to zarathustra_eval\n",
            "[INFO|configuration_utils.py:351] 2021-06-10 18:34:37,301 >> Configuration saved in zarathustra_eval/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-06-10 18:34:38,560 >> Model weights saved in zarathustra_eval/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-06-10 18:34:38,563 >> tokenizer config file saved in zarathustra_eval/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-06-10 18:34:38,567 >> Special tokens file saved in zarathustra_eval/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-10 18:34:39,700 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:39,700 >>   epoch                    =       15.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:39,700 >>   train_loss               =     3.7737\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:39,700 >>   train_runtime            = 0:02:56.10\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:39,700 >>   train_samples            =        100\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:39,700 >>   train_samples_per_second =      8.517\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:39,700 >>   train_steps_per_second   =      2.129\n",
            "06/10/2021 18:34:39 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:2133] 2021-06-10 18:34:39,717 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2135] 2021-06-10 18:34:39,717 >>   Num examples = 23\n",
            "[INFO|trainer.py:2138] 2021-06-10 18:34:39,717 >>   Batch size = 8\n",
            "100% 3/3 [00:00<00:00,  5.01it/s]\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-10 18:34:40,842 >> ***** eval metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   epoch                   =       15.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   eval_loss               =     4.1633\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   eval_runtime            = 0:00:01.11\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   eval_samples            =         23\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   eval_samples_per_second =     20.546\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   eval_steps_per_second   =       2.68\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:34:40,843 >>   perplexity              =    64.2853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftcWMtchBM85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmO_dIc4BM69"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYB6ittsBM4f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imc-N6NMBM2D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-_iRMEKA37K"
      },
      "source": [
        "# PLATO EVAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFbfgA9MA3HI",
        "outputId": "6aed149e-0941-4480-f4b4-8e1c138d9a2b"
      },
      "source": [
        "dataset_file = 'republic.txt'\n",
        "train_set_file = \"republic_train.txt\"\n",
        "val_set_file = \"republic_test.txt\"\n",
        "with open(dataset_file) as dataset_wrapper:\n",
        "  val_split = 0.2\n",
        "  dataset = dataset_wrapper.read()\n",
        "  len_dataset = len(dataset)\n",
        "  randint = random.randint(0,4)\n",
        "  print(randint)\n",
        "  val_start = int(len_dataset * val_split * randint)\n",
        "  val_end = int(len_dataset * val_split * (randint+1))\n",
        "  print(val_start)\n",
        "  print(val_end)\n",
        "  train_set = dataset[:val_start] + dataset[val_end:]\n",
        "  val_set = dataset[val_start:val_end]\n",
        "  print(len(train_set))\n",
        "  print(len(val_set))\n",
        "with open(train_set_file, 'w') as writer_train:\n",
        "    writer_train.write(train_set)\n",
        "with open(val_set_file, 'w') as writer_val:\n",
        "    writer_val.write(val_set)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "513611\n",
            "642014\n",
            "513611\n",
            "128403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZNE8lgsBVwx",
        "outputId": "7ed61cc2-a552-4277-837d-4c210ed11e0f"
      },
      "source": [
        "!python transformers/examples/pytorch/language-modeling/run_clm.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=distilgpt2 \\\n",
        "    --do_train \\\n",
        "    --train_file=republic_train.txt \\\n",
        "    --do_eval \\\n",
        "    --validation_file=republic_test.txt \\\n",
        "    --num_train_epochs 14 \\\n",
        "    --output_dir plato_eval \\\n",
        "    --overwrite_output_dir \\\n",
        "    --save_steps 20000 \\\n",
        "    --per_device_train_batch_size 4"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 18:39:05.747814: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "06/10/2021 18:39:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "06/10/2021 18:39:07 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=runs/Jun10_18-39-07_d80cbc6d5d47,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=14.0,\n",
            "output_dir=plato_eval,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=4,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=plato_eval,\n",
            "save_steps=20000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "06/10/2021 18:39:07 - WARNING - datasets.builder -   Using custom data configuration default-3ca85e55ccf3579b\n",
            "06/10/2021 18:39:07 - WARNING - datasets.builder -   Reusing dataset text (/root/.cache/huggingface/datasets/text/default-3ca85e55ccf3579b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "[INFO|configuration_utils.py:517] 2021-06-10 18:39:08,154 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "[INFO|configuration_utils.py:553] 2021-06-10 18:39:08,154 >> Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:517] 2021-06-10 18:39:08,256 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "[INFO|configuration_utils.py:553] 2021-06-10 18:39:08,257 >> Model config GPT2Config {\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:39:08,873 >> loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:39:08,873 >> loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:39:08,873 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:39:08,873 >> loading file https://huggingface.co/distilgpt2/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:39:08,873 >> loading file https://huggingface.co/distilgpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-06-10 18:39:08,873 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|modeling_utils.py:1155] 2021-06-10 18:39:09,052 >> loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
            "[INFO|modeling_utils.py:1339] 2021-06-10 18:39:10,688 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-06-10 18:39:10,689 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "06/10/2021 18:39:10 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-3ca85e55ccf3579b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-9dac80b4a645abe8.arrow\n",
            "06/10/2021 18:39:10 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-3ca85e55ccf3579b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-31c70f4afa09d9ca.arrow\n",
            "06/10/2021 18:39:10 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-3ca85e55ccf3579b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-aa9fc638db780440.arrow\n",
            "06/10/2021 18:39:10 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-3ca85e55ccf3579b/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-4c57569c963a6782.arrow\n",
            "[INFO|trainer.py:1147] 2021-06-10 18:39:13,380 >> ***** Running training *****\n",
            "[INFO|trainer.py:1148] 2021-06-10 18:39:13,380 >>   Num examples = 107\n",
            "[INFO|trainer.py:1149] 2021-06-10 18:39:13,380 >>   Num Epochs = 14\n",
            "[INFO|trainer.py:1150] 2021-06-10 18:39:13,380 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:1151] 2021-06-10 18:39:13,380 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:1152] 2021-06-10 18:39:13,380 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1153] 2021-06-10 18:39:13,380 >>   Total optimization steps = 378\n",
            "100% 378/378 [02:56<00:00,  2.28it/s][INFO|trainer.py:1343] 2021-06-10 18:42:09,416 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 176.04, 'train_samples_per_second': 8.509, 'train_steps_per_second': 2.147, 'train_loss': 3.5829435479704035, 'epoch': 14.0}\n",
            "100% 378/378 [02:56<00:00,  2.15it/s]\n",
            "[INFO|trainer.py:1887] 2021-06-10 18:42:09,426 >> Saving model checkpoint to plato_eval\n",
            "[INFO|configuration_utils.py:351] 2021-06-10 18:42:09,430 >> Configuration saved in plato_eval/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-06-10 18:42:10,743 >> Model weights saved in plato_eval/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-06-10 18:42:10,747 >> tokenizer config file saved in plato_eval/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-06-10 18:42:10,750 >> Special tokens file saved in plato_eval/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-10 18:42:10,877 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:10,878 >>   epoch                    =       14.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:10,878 >>   train_loss               =     3.5829\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:10,878 >>   train_runtime            = 0:02:56.03\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:10,878 >>   train_samples            =        107\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:10,878 >>   train_samples_per_second =      8.509\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:10,878 >>   train_steps_per_second   =      2.147\n",
            "06/10/2021 18:42:10 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:2133] 2021-06-10 18:42:10,894 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2135] 2021-06-10 18:42:10,894 >>   Num examples = 26\n",
            "[INFO|trainer.py:2138] 2021-06-10 18:42:10,894 >>   Batch size = 8\n",
            "100% 4/4 [00:00<00:00,  5.52it/s]\n",
            "[INFO|trainer_pt_utils.py:907] 2021-06-10 18:42:12,147 >> ***** eval metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,147 >>   epoch                   =       14.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,148 >>   eval_loss               =     3.8514\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,148 >>   eval_runtime            = 0:00:01.24\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,148 >>   eval_samples            =         26\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,148 >>   eval_samples_per_second =      20.86\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,148 >>   eval_steps_per_second   =      3.209\n",
            "[INFO|trainer_pt_utils.py:912] 2021-06-10 18:42:12,148 >>   perplexity              =    47.0585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L3s3iCWBVuo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avx_VZ2_BVsI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCZJViifBVpz",
        "outputId": "199f44ef-913b-465f-db0d-40fa80f5f061"
      },
      "source": [
        "!python transformers/examples/pytorch/text-generation/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=plato_eval \\\n",
        "--num_return_sequences 5 \\\n",
        "--length 150 \\"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/10/2021 17:47:47 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "06/10/2021 17:47:51 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=150, model_name_or_path='plato_eval', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is the meaning of life?\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-06-10 17:47:59.436207: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "What is the meaning of life? He has no idea how it happens, and he has no idea how it is portrayed. It's not the end of all life, and the end of all what is true, but how it ends.\n",
            "I must ask myself: Were there any emotions and desires that would strike at us that hurt our best yet in other ways?\n",
            "I will do it at once, but if there are many possibilities in life, I must ask myself: was there any of those feelings or desires that would strike at us that hurt our best yet in other ways? Yes, and then there are many other emotions, but I will only speak so only if they are all within our grasp. If the god has made sense, and he has no idea how the\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "What is the meaning of life?›<gouches>From…go. Look at all the flowers and sweet ladys of the world who, for their making of their divine body and make themselves great of evil, suddenly cease to enjoy themselves, and take no action to please them? ›<gouches>We may enjoy the beauty of the beauty of the perfume of the garden; but then, now, when the people around you have been compelled to move at least sevenfold, will you in their favour let us put them into the garden? Shall they then keep only one another, or tenfold, as does the rest of the people? Would you give them only a single part of their body? Our people will want to change, too? But\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "What is the meaning of life? Will the consciousness allow consciousness to drive us beyond time and space? The philosophy of mathematics are about complexity: the answers must be the science of the cosmos. I cannot imagine how we could think otherwise. Suppose we could imagine the universe as having its own grand nature; then, in fact, they would say that such a universe existed no other than the one represented by a little change. They all move, from time to time, as it is normal to feel that another is in the same category. But imagine the universe as having a grand nature, one that is as direct as to the elements. There is no possible balance between that simple and the complex of complex-complexity. For there is no difference in the nature of the cosmos. And\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "What is the meaning of life? Where, I will say, it is no different from that of a human being. That is not to say, it is not how nature is. This is not, of course, just the word \"nature\" and this is not a word which means to be said to be said to be a wholly different thing than that which it is described in terms of nature. Nor is it this and that does not affect your attention to your own person?\n",
            "\n",
            "I will say, it is true, that the meaning of life is a kind of matter of some kind, which we do not call nature or what is called a state. But also there is some difference between the meaning of life, and the meaning of life itself. For one thing,\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "What is the meaning of life?\n",
            "I shall devote myself to knowing.\n",
            "A second. For everything that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow, let the order produce. For all things that must follow,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXy5b5R1CYEh"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}